version: '3.8'
services:
  # Reverse proxy authenticating requests and routing them to the Ollama service
  traefik:
    image: traefik:v2.5
    restart: unless-stopped
    command:
      # - "--api.insecure=true" # Enables the dashboard and API insecurely
      # - "--log.level=DEBUG" # Adjust the log level as needed (DEBUG, INFO, WARN, ERROR, FATAL, PANIC)
      # - "--accesslog=true" # Enables access logs
      - "--providers.docker=true"
      - "--providers.docker.exposedByDefault=false"
      - "--providers.file.filename=/etc/traefik/certs/dynamic_conf.yml"   # Configures TLS certs
      - "--entrypoints.websecure.address=:443"
    ports:
      - "443:443"
      # - "8080:8080" # Expose port 8080 for the dashboard
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "./certs/webservice:/etc/traefik/certs"   # Mount TLS certs into container
      - "./traefik/dynamic_conf.yml:/etc/traefik/certs/dynamic_conf.yml"  # Mount TLS config into container
    networks:
      - web
  
  # LLM inference service Ollama
  ollama:
    image: ollama/ollama
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ollama.rule=Host(`spezillmfog.local`)"
      - "traefik.http.routers.ollama.entrypoints=websecure"
      - "traefik.http.routers.ollama.tls=true"
      - "traefik.http.routers.ollama.service=ollama-service"
      - "traefik.http.services.ollama-service.loadbalancer.server.port=11434"
      - "traefik.http.routers.ollama.middlewares=auth@docker"
      - "traefik.http.middlewares.auth.forwardauth.address=http://auth-service:3000/"
      - "traefik.http.middlewares.auth.forwardauth.trustForwardHeader=true"
    volumes:
      - ollama_storage:/root/.ollama
    networks:
      - web

  # Authorizes incoming LLM inference requests
  auth-service:
    build:
      context: auth
    hostname: auth-service
    restart: unless-stopped
    environment:
      - PORT=3000
      # Adjust if using the Firebase emulator
      # - USE_FIREBASE_EMULATOR=true
      # - FIREBASE_AUTH_EMULATOR_HOST=localhost:9099
      # - FIREBASE_PROJECT_ID=spezillmfognode
    labels:
      - "traefik.enable=false"
    volumes:
      - ./auth/serviceAccountKey.json:/usr/src/app/serviceAccountKey.json  # Adjust the host mount location as needed
    networks:
      - web

  # On the Linux platform, advertise LLM inference service via mDNS from Avahi
  avahi:
    build:
      context: avahi
    hostname: spezillmfog.local
    network_mode: host  # Need to run in host network mode for mDNS 
    profiles:
      - linux
    restart: unless-stopped

# Enables persistence of downloaded LLMs by Ollama
volumes:
  ollama_storage:

networks:
  web:
    driver: bridge
